Unitree Go2 PHM 프로젝트
교수님 발표용 초상세 설명서
작성일: 2026-02-14

========================================================================
문서 사용법
========================================================================

이 문서는 3가지 상황에서 바로 사용할 수 있도록 만들었습니다.

1) 교수님 면담 직전:
- "전체 그림"만 빨리 읽고 싶으면
  1장(프로젝트 개요), 2장(용어 사전), 4장(연구 큰 그림), 13장(미팅 대본)
  먼저 읽으시면 됩니다.

2) 교수님 질문 대응:
- "이 코드가 정확히 어떤 순서로 도는가", "왜 이 비교가 공정한가",
  "실로봇 전이 시 어떤 위험이 있는가" 같은 질문이 나오면
  3장(실행 흐름), 6장(코드 구조), 8장(실험/평가), 18.4~18.6(sim-to-real)
  를 보시면 바로 답할 수 있습니다.

3) 실제 실행 준비:
- "내가 뭘 언제 해야 하는지"만 확인하려면
  14장(실행 계획), 15장(실수 방지 체크리스트), 16장(파일 산출물 체크)
  를 보시면 됩니다.


========================================================================
1장. 30초 프로젝트 개요 (교수님 첫 설명용)
========================================================================

한 줄 핵심:
"로봇이 열/전압/기계 열화 상태를 고려해서 넘어지지 않고 오래 걷도록
 정책을 학습시키는 프로젝트입니다."

조금 더 길게:
- 기존 보행정책은 '지금 당장 잘 걷기'에만 집중하는 경우가 많습니다.
- 이 프로젝트는 "건강 상태(온도, 전압, 피로도)"를 같이 고려해서
  보행 전략을 바꾸도록 만듭니다.
- 결과적으로 열화된 상태에서도 생존률/추종성능/안전성이 개선되는지
  정량 평가합니다.

핵심 기여 구조(교수님께 이렇게 설명):
1) 열화 물리를 시뮬레이션 물리 루프에 일관되게 주입
2) 정책 관측을 3가지 단계로 분리(Privileged, Baseline, RealObs)
3) 고정 명령 replay에서 governor ON/OFF로 안전-성능 tradeoff 검증
4) Teacher-Student로 latent 의존을 낮춰 RealObs 정책으로 이전

1.1 하이퍼파라미터/DR 범위를 정한 외부 근거 (질문 대비용)

아래 3개를 "기준 문헌"으로 고정해서 설명하면 됩니다.

1) Learning to Walk in Minutes (arXiv:2109.11978)
- 링크: https://arxiv.org/abs/2109.11978
- 우리에게 준 기준:
  - 대규모 병렬 학습 구조(4096급 env)
  - curriculum + domain randomization 기본 철학

2) legged_gym 공개 구현(ETH)
- 링크: https://github.com/leggedrobotics/legged_gym
- 우리에게 준 기준:
  - PPO 실무 기본값 관행(예: `n_steps=24`, entropy 기본 세팅)
  - Isaac Gym 계열 재현 실무 레퍼런스

3) Curriculum Jumping for Quadrupeds (arXiv:2401.16337)
- 링크: https://arxiv.org/abs/2401.16337
- 우리에게 준 기준:
  - DR 상한선 감각(질량/마찰/지연/오프셋)
- 주의:
  - 점프 과제라 난도가 높음
  - 보행 프로젝트인 우리는 그대로 복사하지 않고 "축소/완화"해서 적용

교수님께 한 문장으로 답할 때:
- "PPO 뼈대는 2109.11978/legged_gym을 따르고, DR 범위의 상한 감각은 2401.16337을 참고하되 Go2 보행 안정성에 맞게 보수적으로 줄였습니다."


========================================================================
2장. 용어 사전 (프로젝트 공통 용어)
========================================================================

2.1 꼭 알아야 하는 최소 용어

1) Environment (Env)
- 강화학습에서 "실험 시스템 1개"를 의미합니다.

2) num_envs
- 동시에 돌리는 Env 개수입니다.
- 예: 4096이면 4096개 로봇 실험을 병렬로 동시에 진행.

3) Episode
- 초기화부터 종료(넘어짐/시간초과/안전종료)까지 1회 실험.

4) Policy
- 상태(관측)를 넣으면 액션(관절 목표)을 내는 신경망 함수.

5) Reward
- "이 행동이 좋은지" 점수.
- RL은 reward 총합이 커지도록 policy를 자동 조정.

6) PPO
- 정책을 조금씩 안정적으로 업데이트하는 RL 알고리즘.

7) Privileged observation
- 실제 로봇에서 바로 측정 못하는 내부 상태까지 보는 관측.

8) RealObs (Real-observable)
- 실제 로봇에서 측정 가능한 채널 중심 관측.

9) Governor
- 명령을 그대로 통과시키지 않고, 온도/전압 위험도에 따라
  자동으로 축소하는 안전 스케일러.

10) Fault injection
- 특정 다리 Kp/Kd를 인위적으로 떨어뜨려 고장 상황을 모사.


2.2 이 프로젝트에서 자주 나오는 지표

1) survival (%)
- 에피소드가 끝까지 버틴 비율.

2) tracking error
- 목표 속도와 실제 속도 차이.

3) mean power / total energy
- 평균 전력 / 누적 에너지.

4) final max temp
- 에피소드 끝 시점 최대 온도.

5) vpack_min / vcell_min
- 최저 팩 전압 / 최저 셀 전압.

6) max saturation
- 모터 토크가 한계에 얼마나 자주 붙는지.


========================================================================
3장. 코드가 실제로 돌아가는 순서 (함수 단위 상세)
========================================================================

3.1 학습 스크립트 시작점

파일:
- unitree_go2_phm/scripts/rsl_rl/train.py

실행 흐름:
1) argparse로 task/seed/num_envs/max_iterations 로드
2) gym.make(task, cfg=env_cfg)로 환경 생성
3) RslRlVecEnvWrapper로 wrapper 적용
4) OnPolicyRunner 생성
5) runner.learn()로 PPO 반복

핵심:
- 실제 동역학 계산은 train.py가 아니라 Env 내부 step()에서 수행됩니다.


3.2 환경 초기화 순서

파일:
- source/.../unitree_go2_phm/unitree_go2_phm_env.py

호출 순서:
1) UnitreeGo2PhmEnv.__init__()
2) load_managers()에서 init_phm_interface(self) 호출
3) phm_state, buffer, joint index, actuator binding 세팅
4) brownout 관련 상수/threshold 캐시

중요:
- 여기서 PHM 상태 텐서가 생성되므로, 이후 관측/보상/종료는
  phm_state를 공통 데이터 소스로 읽습니다.


3.3 한 스텝(50Hz) 내부 실행 순서

핵심 함수:
- UnitreeGo2PhmEnv.step(action)

순서:
1) clear_step_metrics(self)
2) action_manager.process_action()
3) refresh_phm_sensors(self)
4) decimation 루프(4회, 200Hz 물리):
   - substep 0: action_manager.apply_action()
   - substep 0: _predict_instant_voltage_ivp(...)
   - substep 0: brownout latch/scale 갱신
   - substep 0: _compute_thermal_limits(), _apply_physical_degradation()
   - physics step
   - update_phm_dynamics(self, physics_dt)
   - min_voltage_log 업데이트
5) termination_manager.compute()
6) reward_manager.compute()
7) done env reset (_reset_idx)
8) command/event 갱신
9) observation_manager.compute()

중요:
- 전압 예측/안전스케일/열화게인 적용이 substep 0에 정렬되어
  한 스텝 지연(stale action) 문제가 줄어들도록 되어 있습니다.


3.4 reset 경로

핵심 함수:
- UnitreeGo2PhmEnv._reset_idx()
- phm/interface.py::reset_phm_interface()

역할:
1) env 기본 reset
2) PHM state reset
3) 커리큘럼 기반 fatigue/temp/soc 재초기화
4) degraded gain 및 effort limit 재계산
5) reset 직후 관측/물리 일관성 맞춤


3.5 평가 스크립트별 차이

1) evaluate.py
- 시나리오(fresh/used/aged/critical) 강제 주입
- 에피소드 통계 중심 결과 JSON 생성

2) evaluate_replay.py
- 고정 command file 입력
- governor ON/OFF, fault injection 비교
- step CSV + summary JSON 생성


========================================================================
4장. 연구 큰 그림 (문제-방법-검증)
========================================================================

4.1 문제 정의

기본 보행 정책은 건강한 상태에서만 잘 동작하고,
열화(고온, 저전압, 마모) 상황에서 급격히 성능이 떨어질 수 있습니다.

연구 질문:
"건강 상태를 고려하면 열화 조건에서도 더 안전하고 강건하게 걸을 수 있는가?"


4.2 해결 전략

1) PHM 물리 상태를 내부적으로 계산
- 온도, 피로도, SOC/전압, 포화, 스톨

2) 정책 입력 설계 분리
- Phm-v1: latent 포함(상한 성능 확인)
- Baseline-v1: PHM 관측 제거(공정 비교군)
- RealObs-v1: 실측 가능 채널 중심(메인 주장)

3) 정량 평가
- 시나리오 평가(fresh/used/aged/critical)
- 고정 replay + governor ON/OFF + fault

4) 전이 전략
- Teacher(Privileged) -> Student(RealObs) distillation


4.3 기대 결과 형태

1) Fresh:
- Baseline과 PHM 정책 성능 유사 (성능 손해 없음 확인)

2) Aged/Critical:
- PHM 또는 RealObs+governor가 survival/안전성에서 우위

3) Replay:
- governor ON이 온도/전압 위험 노출시간 감소
- 추종오차 희생은 제한적


========================================================================
5장. 이 코드가 실제로 구현한 것 (한눈에)
========================================================================

핵심 태스크 3개:
- Unitree-Go2-Phm-v1
- Unitree-Go2-Baseline-v1
- Unitree-Go2-RealObs-v1

핵심 스크립트:
- train.py                 : PPO 학습
- evaluate.py              : 시나리오 평가
- evaluate_replay.py       : 고정 커맨드 replay 평가
- distill_teacher_student.py : teacher-student distillation
- compare_replay_summaries.py: replay 결과 비교

핵심 환경 파일:
- unitree_go2_phm_env.py
- unitree_go2_phm_env_cfg.py
- unitree_go2_baseline_env_cfg.py
- unitree_go2_realobs_env_cfg.py

PHM 핵심 모듈:
- phm/interface.py
- phm/state.py
- phm/models/thermal.py
- phm/models/degradation.py
- phm/utils.py


========================================================================
6장. 코드 구조 상세 설명 (파일별 역할)
========================================================================

6.1 태스크 등록

파일:
- source/.../unitree_go2_phm/__init__.py

역할:
- Gym 태스크 이름과 cfg/agent 연결
- 여기서 3개 태스크 ID가 등록됨


6.2 환경 설정 (cfg)

1) unitree_go2_phm_env_cfg.py
- PHM full 관측/보상/종료 설정

2) unitree_go2_baseline_env_cfg.py
- 같은 물리 + PHM 관측/보상 제거

3) unitree_go2_realobs_env_cfg.py
- 실측 중심 관측/보상/종료 기준 설정
- brownout source를 sensor_voltage로 설정
- thermal termination은 case-proxy 기준(현재 기본 활성)으로 동작


6.3 환경 실행 본체

파일:
- unitree_go2_phm_env.py

핵심:
- 50Hz 제어 + 200Hz 물리 decimation 루프
- brownout latch/scale 관리
- degraded Kp/Kd, effort limits 적용
- step metric logging 및 terminal snapshot 보존


6.4 PHM 인터페이스

파일:
- phm/interface.py

역할:
- applied torque/velocity 기반으로 fatigue/thermal/voltage 업데이트
- sensor noise 재샘플링
- reset 시 시나리오/커리큘럼 초기화
- long-term/short-term buffer 갱신


6.5 보상/관측/종료 분리 모듈

파일:
- mdp/observations/*.py
- mdp/rewards/*.py
- mdp/terminations/*.py

장점:
- "어떤 입력을 보게 할지"
- "무엇을 보상할지"
- "어떤 안전 기준에서 종료할지"
를 독립적으로 제어 가능


========================================================================
7장. 실제 물리/신호 흐름 (교수님 설명용 순서)
========================================================================

이 장은 "로봇 내부에서 무슨 일이 일어나는가"를 순서대로 설명합니다.

7.1 정책 액션 생성
- policy가 관측을 받아 관절 목표에 해당하는 액션 생성

7.2 액션 적용
- substep 0에서 액션 적용
- 이후 물리 엔진이 실제 토크를 계산/적용

7.3 PHM 상태 갱신
- 실제 applied torque, joint vel로 피로도/전력/온도 업데이트
- 전압/소모에너지/SOC 업데이트

7.4 안전 상태 갱신
- brownout latch(저전압 진입/회복 히스테리시스)
- thermal derating
- torque saturation/stall timer

7.5 보상/종료 판정
- locomotion + PHM reward 계산
- 낙상/열폭주/스톨 등 termination 검사

7.6 reset 처리
- 종료된 env만 reset
- 시나리오 조건 재주입 가능
- reset 후 관측 동기화


========================================================================
8장. 실험 설계 (논문 결과를 만드는 절차)
========================================================================

8.1 학습 단계

권장 1차 학습:
1) PHM policy 학습 (Unitree-Go2-Phm-v1)
2) Baseline policy 학습 (Unitree-Go2-Baseline-v1)
3) 필요시 seed 3회 반복

출력:
- logs/rsl_rl/<experiment>/<timestamp>/model_*.pt


8.2 시나리오 평가 단계

evaluate.py로 fresh/used/aged/critical에서 정량화:
- survival
- tracking error
- power/energy
- SOC/temp/fatigue/SOH/saturation

출력:
- eval_*.json
- eval_*_meta.json (온도 metric semantics 포함)


8.3 replay 평가 단계

evaluate_replay.py:
- 고정 command file 사용
- governor ON/OFF 비교
- fault injection 시점/다리/Kp-Kd 고정

출력:
- trial_XX_steps.csv (시계열)
- summary.json (집계 지표)


8.4 distillation + finetune 단계

1) Teacher(Phm-v1 checkpoint) 준비
2) distill_teacher_student.py 실행
3) student_distill_final.pt 획득
4) RealObs PPO finetune
5) replay 평가로 최종 성능 확인


========================================================================
9장. 교수님이 특히 이해하기 어려울 수 있는 포인트 (미리 방어)
========================================================================

9.1 "latent"와 "측정값" 차이

1) latent:
- 시뮬레이션 내부에서 계산한 지표(예: mech_health)
- 실로봇에서 직접 같은 이름으로 측정 불가

2) 측정값:
- 실제 로봇에서 바로 로그 가능(온도, 전압, 전류, q/dq/tau_est, IMU 등)

논문 원칙:
- 메인 claim은 측정 가능한 채널 기준으로 작성
- latent는 teacher/분석/보조 설명으로 제한


9.2 "온도 기준이 왜 두 가지인가"

1) coil hotspot:
- 내부 권선 중심의 더 뜨거운 지점(보통 직접 측정 어려움)

2) case/housing temp:
- 실제 센서로 받는 외피 근처 온도(느리고 낮게 반응)

현재 코드:
- privileged는 coil semantics, RealObs는 case semantics를 명시적으로 분리
- 열 상태도 coil/case 2-node 동역학으로 함께 업데이트

논문 작성 시 필수:
- 표/그림 캡션에 해당 metric semantics 명시


9.3 "baseline도 PHM 물리를 쓰는가"

네, baseline도 PHM 물리는 동일하게 적용됩니다.
차이는 "정책이 PHM 정보를 보느냐/안 보느냐"입니다.
그래서 비교가 공정합니다.


========================================================================
10장. Governor 상세 (교수님에게 수식/의미 설명)
========================================================================

10.1 입력 신호
- T = max motor temperature
- Vcell_min = min cell voltage
- Vpack = pack voltage

10.2 필터
- 온도 EMA: tau=1.0s
- 전압 EMA: tau=0.2s

10.3 예측
- T_pred = T_ema + horizon * dT/dt

10.4 스케일 계산

온도 스케일:
s_T = clamp((T_crit - T_pred)/(T_crit - T_warn), 0, 1)

전압 스케일:
s_V = clamp((Vcell - V_soft_stop)/(V_warn - V_soft_stop), 0, 1)^2

최종 스케일:
s = min(s_T, s_V)

명령 적용:
vx_exec = s * vx_ref
vy_exec = s * vy_ref
wz_exec = s^(yaw_exp) * wz_ref

10.5 hard-stop
- T >= T_stop 또는
- Vpack <= pack_stop 또는
- Vcell <= cell_hard_stop

기본값:
- temp 65/70/72 C
- cell 3.20/3.05/3.00 V
- pack 24.5 V
- yaw_exp 1.5


========================================================================
11장. 논문에서 "써도 되는 주장"과 "절대 조심할 주장"
========================================================================

11.1 써도 되는 주장

1) 시뮬레이션 열화 물리 동일 조건에서 PHM-aware 우위
2) RealObs + governor가 replay 안전 지표 개선
3) distillation으로 privileged 행동을 RealObs로 이전 가능


11.2 조심할 주장

1) latent 지표를 실측처럼 직접 주장 금지
2) 온도 semantics를 섞어서 단일 숫자로 오해시키지 말 것
3) sim 결과만으로 "실로봇도 반드시 동일" 식 과장 금지


11.3 본문에서 권장 문장 스타일

1) "In simulation, under matched degradation dynamics, ..."
2) "For real-observable claims, we report metrics based on measurable channels ..."
3) "Privileged latent signals are used for teacher/analysis, not as direct real measurements."


========================================================================
12장. 교수님 질문 예상 Q/A
========================================================================

Q1. 왜 굳이 RL을 써야 하나?
A1.
- PHM 상태와 보행 제어의 결합이 비선형/시변이기 때문입니다.
- 수동 규칙만으로는 모든 조합(온도, 전압, 지면, 고장)을 커버하기 어렵고,
  RL은 시뮬레이션 병렬 반복으로 전략을 학습합니다.

Q2. 왜 baseline과 PHM 둘 다 필요한가?
A2.
- 공정 비교를 위해서입니다.
- 물리는 같고, 정보/목표만 다르게 해서 "PHM 정보의 효과"를 분리합니다.

Q3. 왜 RealObs를 따로 만들었나?
A3.
- 논문 claim을 실제 측정 가능한 채널에 맞추기 위함입니다.
- 실로봇 전이 관점에서 가장 안전한 메인 트랙입니다.

Q4. 왜 governor가 필요한가?
A4.
- 정책이 항상 안전 경계를 보장하지 않을 수 있으므로,
  마지막 안전 계층으로 명령을 축소/정지시키기 위해 필요합니다.

Q5. 이게 실로봇에서도 바로 되나?
A5.
- SDK 연동 + 실로그 채널 정합 + 임계값 검증이 필요합니다.
- 현재는 그 경로를 위한 코드/요구사항 문서까지 준비된 상태입니다.


========================================================================
13장. 교수님 미팅 대본 (30~40분 버전)
========================================================================

13.1 5분 요약 발표 스크립트

1) 문제:
"열화 상태에서 기존 보행정책이 무너질 수 있습니다."

2) 방법:
"열/전압/피로 물리를 환경에 주입하고,
 정책 입력과 보상을 PHM-aware로 설계했습니다."

3) 검증:
"baseline 대비 시나리오/리플레이에서 안전성과 강건성 차이를 정량화합니다."

4) 전이:
"실측 가능 채널 중심 RealObs 정책 + governor로 메인 claim을 구성합니다."

5) 의사결정 요청:
"실험 우선순위와 투고 포지션(PHM 중심 vs Robotics 중심) 확정 부탁드립니다."


13.2 15분 상세 스크립트

1) 3개 태스크 구조 설명 (Phm/Baseline/RealObs)
2) PHM 동역학(피로/열/전압) 물리 흐름 설명
3) reward/termination 설계 이유 설명
4) evaluate + replay 지표 설명
5) teacher-student 전이 이유 설명
6) claim 범위와 제한(측정가능성) 명확화


13.3 마지막 5분 교수님 질문 유도

1) "실로봇 실험 안전 임계값은 현재 값으로 승인 가능하신지"
2) "fault 모델을 RL 다리 고정으로 갈지, 추가 하드웨어 fault를 더 넣을지"
3) "메인 도표를 replay 중심으로 둘지 시나리오 중심으로 둘지"


========================================================================
14장. 내가 실제로 해야 할 일 (실행 플랜)
========================================================================

14.1 이번 주 해야 할 일 (1주 플랜)

Day 1:
- 실험 설정 freeze (태스크/threshold/seed/체크포인트 규칙)
- 실행 스크립트 인자 템플릿 확정

Day 2:
- PHM/Baseline 학습 수행 (최소 seed 1, 가능하면 seed 3)

Day 3:
- evaluate.py로 4시나리오 평가
- 결과 JSON 정리

Day 4:
- teacher distill + student finetune

Day 5:
- replay 3개 시나리오 ON/OFF + fault 평가
- summary 비교표 생성

Day 6:
- 교수님 발표자료 작성
- 질문 대응 Q/A 준비

Day 7:
- 교수님 피드백 반영 후 실험 추가


14.2 다음 주 해야 할 일 (2주차)

1) 선택된 메인 그림/표 고정
2) ablation 최소 세트 수행
3) 문장화(방법/실험/한계) 시작
4) 실로봇 로그 계획 확정


========================================================================
15장. 실수 방지 체크리스트 (중요)
========================================================================

15.1 실험 공정성 체크

1) Baseline과 PHM의 물리 설정이 동일한가?
2) seed/num_envs/iteration 등 학습 예산이 동일한가?
3) checkpoint 선택 기준이 공정한가? (최종 혹은 동일 룰)


15.2 해석 오류 방지

1) 온도 metric semantics를 표/캡션에 명시했는가?
2) latent 지표를 실측처럼 서술하지 않았는가?
3) replay와 scenario 결과를 섞어 과장하지 않았는가?


15.3 실행 오류 방지

1) evaluate_replay는 num_envs=1인지 확인
2) output_dir를 run별로 분리했는지 확인
3) summary.json과 trial csv가 모두 생성됐는지 확인


15.4 문서 오류 방지

1) 임계값(65/70/72, 3.20/3.05/3.00, 24.5)이 코드와 일치하는가?
2) 표 숫자가 실제 JSON 집계값과 일치하는가?
3) "예시 숫자"와 "실측 숫자"를 명확히 구분했는가?


========================================================================
16장. 산출물 체크 (논문/발표용 파일 목록)
========================================================================

학습 산출물:
- logs/rsl_rl/<exp>/<run>/model_*.pt
- logs/rsl_rl/<exp>/<run>/params/env.yaml
- logs/rsl_rl/<exp>/<run>/params/agent.yaml

시나리오 평가 산출물:
- eval_results/.../eval_*.json
- eval_results/.../eval_*_meta.json

replay 평가 산출물:
- replay_results/.../trial_XX_steps.csv
- replay_results/.../summary.json

distillation 산출물:
- logs/rsl_rl/unitree_go2_realobs/<run>/student_distill_final.pt
- distill_summary.json

발표 문서:
- PROFESSOR_PRESENTATION_PREP_KR_ULTRA_DETAIL.txt (현재 파일)
- PROFESSOR_PRESENTATION_PREP_KR.txt (요약본)
- EXPERIMENT_GUIDE.md (실행 가이드)


========================================================================
17장. 폴더/파일 지도 (교수님께 "어디를 보면 되는지")
========================================================================

프로젝트 루트:
- /home/iamjaehka13/unitree_go2_phm

핵심 문서:
- EXPERIMENT_GUIDE.md
- PROFESSOR_PRESENTATION_PREP_KR_ULTRA_DETAIL.txt

실험 스크립트:
- unitree_go2_phm/scripts/rsl_rl/train.py
- unitree_go2_phm/scripts/rsl_rl/evaluate.py
- unitree_go2_phm/scripts/rsl_rl/evaluate_replay.py
- unitree_go2_phm/scripts/rsl_rl/distill_teacher_student.py

환경/PHM 코드:
- unitree_go2_phm/source/unitree_go2_phm/.../unitree_go2_phm_env.py
- unitree_go2_phm/source/unitree_go2_phm/.../unitree_go2_phm_env_cfg.py
- unitree_go2_phm/source/unitree_go2_phm/.../unitree_go2_realobs_env_cfg.py
- unitree_go2_phm/source/unitree_go2_phm/.../phm/interface.py
- unitree_go2_phm/source/unitree_go2_phm/.../phm/state.py

실로봇 준비:
- unitree_go2_phm/scripts/real/README.md
- unitree_go2_phm/scripts/real/REAL_LOG_REQUIREMENTS.txt
- third_party/unitree_sdk2/


========================================================================
18장. 명령어를 "인자까지" 이해하기 (교수님 설명용)
========================================================================

18.1 train.py 예시

명령:
python unitree_go2_phm/scripts/rsl_rl/train.py \
  --task Unitree-Go2-Phm-v1 \
  --num_envs 4096 \
  --max_iterations 3000 \
  --headless

인자 뜻:
- --task:
  어떤 환경 정의로 학습할지
- --num_envs:
  병렬 시뮬레이션 개수
- --max_iterations:
  PPO 업데이트 반복 횟수
- --headless:
  GUI 없이 실행(서버 학습에 필수)


18.2 evaluate.py 예시

명령:
python unitree_go2_phm/scripts/rsl_rl/evaluate.py \
  --task Unitree-Go2-Phm-v1 \
  --checkpoint <path>/model_2999.pt \
  --num_envs 512 \
  --num_episodes 100 \
  --output_dir ./eval_results/phm \
  --headless

핵심:
- 학습된 정책을 고정하고 정량 평가만 수행
- 시나리오별 집계 결과 JSON 출력


18.3 evaluate_replay.py 예시

명령:
python unitree_go2_phm/scripts/rsl_rl/evaluate_replay.py \
  --task Unitree-Go2-RealObs-v1 \
  --checkpoint <student_ckpt> \
  --command_file unitree_go2_phm/scripts/rsl_rl/replay_commands/s1_thermal_cruise.yaml \
  --num_trials 3 \
  --governor \
  --fault_leg RL \
  --fault_kp_scale 0.6 \
  --fault_start_s 5.0 \
  --risk_factor_fixed 1.0 \
  --output_dir ./replay_results/on_fault \
  --headless

핵심:
- 고정 커맨드 시나리오 반복으로 비교 가능성 확보
- governor/fault를 켜고 끄며 ablation 수행


18.4 sim-to-real 전이 시 실제로 자주 깨지는 지점 (핵심)

아래는 "왜 시뮬레이션에서는 잘 되는데 실기에서 다르게 보이는지"에 대한
대표 원인과 대응입니다.

1) 온도 채널 의미 불일치
- 원인:
  sim은 coil_temp(핫스팟 중심) 기반인데, 실기 로그는 case/housing 온도
  (느리고 낮은 값)일 가능성이 큼.
- 증상:
  실기에서 governor가 늦게 반응하거나, 반대로 너무 보수적으로 반응.
- 대응:
  - RealObs 경로를 case-proxy semantics로 통일
  - 표/그림에 온도 metric semantics 명시
- 코드 지점:
  - `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/mdp/observations/phm_raw.py`
  - `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/mdp/rewards/phm.py`
  - `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/mdp/terminations/health.py`

2) 샘플링 주기/타임스탬프 불일치
- 원인:
  실기 수신은 500Hz 패킷이지만 정책/거버너 루프는 50Hz.
  다운샘플 방식(평균/마지막값/최댓값)이 다르면 결과가 크게 달라짐.
- 증상:
  동일 로그에서도 재현시 time_over_warn, min_voltage가 run마다 흔들림.
- 대응:
  - 500Hz 원본을 유지하고, 20ms 윈도우 집계 규칙을 고정
  - T는 max, Vcell은 min, Vpack은 last 또는 mean으로 규칙 문서화
- 코드 지점:
  - `unitree_go2_phm/scripts/real/REAL_LOG_REQUIREMENTS.txt` 기준으로 전처리
  - replay 입력 생성 로직(신규 스크립트)에서 집계 규칙 고정

3) 명령 인터페이스 차이
- 원인:
  sim 액션 경로와 실기 제어 경로(q_des + Kp/Kd)의 내부 동작 차이.
- 증상:
  같은 명령인데 실기 추종 오차가 체계적으로 큼.
- 대응:
  - 실기 low-level 제어 모드 고정
  - fault injection도 실기에서 동일 의미(예: 특정 다리 Kp 스케일)로 정의
- 코드 지점:
  - sim fault profile: `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/unitree_go2_phm_env.py`
  - replay fault 인자: `unitree_go2_phm/scripts/rsl_rl/evaluate_replay.py`

4) 토크 신호 의미 차이
- 원인:
  sim은 applied_torque(물리엔진 실제 적용치), 실기는 tau_est(추정치) 사용.
- 증상:
  에너지/포화/스톨 지표가 절대값 기준으로 바로 일치하지 않음.
- 대응:
  - 절대값 일치보다 "상대 변화" 및 "임계 초과 시간" 중심으로 비교
  - tau_est 기반 보정계수를 로그에서 추정하여 적용 가능
- 코드 지점:
  - 동역학 업데이트: `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/phm/interface.py`

5) 배터리 모델 차이
- 원인:
  sim의 OCV+sag 근사 모델과 실배터리/BMS 응답 불일치.
  (현재 코드는 회생 시 인위적 전압상승 경로를 제거해 내부 정합성은 개선)
- 증상:
  vpack_min, brownout 시점 차이.
- 대응:
  - real 로그로 cutoff margin 재보정
  - governor threshold는 실로그 기준으로 미세조정
- 코드 지점:
  - 배터리 모델: `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/phm/utils.py`
  - brownout source/threshold: `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/unitree_go2_realobs_env_cfg.py`
  - replay governor: `unitree_go2_phm/scripts/rsl_rl/replay_utils.py`

6) 종료/안전 모드 전환 타이밍
- 원인:
  실기에서는 보호 로직(BMS, SDK safety, E-stop)이 별도로 개입 가능.
- 증상:
  원인 분류가 모호한 조기 종료.
- 대응:
  - stop reason을 temp/pack/cell/estop/mode-change로 분리 로깅
  - 실험 보고서에 우선 종료 원인 카운트 포함
- 코드 지점:
  - replay summary reason: `unitree_go2_phm/scripts/rsl_rl/evaluate_replay.py`


18.5 real 로그를 어떻게 사용해 코드에 반영할지 (실무 절차)

절차는 반드시 "raw 보존 -> 표준화 -> 50Hz 파생 -> 파라미터 보정 -> 코드 반영"
순서로 진행하는 것이 안전합니다.

1) Raw 로그 수집 (500Hz, 동기 패킷)
- 수집 필드:
  motor temp 12, q/dq/tau_est 12, vpack/current/soc/cell8, imu, foot/contact,
  command(vx,vy,wz), mode flag, tick
- 원본은 가공 없이 보존(추후 감사/재현성).

2) 표준 스키마로 변환
- 권장 컬럼:
  `ts`, `vx_cmd`, `vy_cmd`, `wz_cmd`,
  `temp_m1..m12`, `tau_est_m1..m12`, `dq_m1..m12`,
  `vpack`, `vcell_0..7`, `soc`, `imu_*`, `foot_*`, `mode`, `estop`
- 단위 명시:
  degC, V, A, rad, rad/s.

3) 50Hz 분석 뷰 생성(20ms 윈도우)
- 파생 신호:
  `T_case_max = max(temp_m1..m12)`
  `Vcell_min = min(vcell_0..7)`
  `Vpack_50hz = last(vpack)` 또는 mean(규칙 고정)
  `wz_actual`(가능한 경우), `wz_cmd`
- 주의:
  윈도우 경계/집계 연산 규칙을 고정해야 run간 비교 가능.

4) 파라미터 보정
- 보정 대상:
  `temp_warn/crit/stop`, `cell_warn/soft/hard`, `pack_stop`,
  `temp_filter_tau`, `volt_filter_tau`, `yaw_exponent`,
  `coil_to_case_delta_c`(case 직접 채널이 없을 때).
- 방법:
  실로그에서 과열/저전압 직전 구간 분포를 보고 margin 설정.

5) 코드 반영 + 재평가
- replay ON/OFF 동일 command로 재실행
- `time_temp_over_warn`, `completed_rate`, `yaw_mae_exec` 변화 확인
- stop reason 분해 통계 확인


18.6 "어디를 수정해야 하는지" 파일 단위 맵

아래는 목적별 수정 위치입니다.

1) RealObs 관측식 조정(전압/온도 의미)
- 파일:
  - `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/mdp/observations/phm_raw.py`
- 주요 함수:
  - `available_voltage_budget_realobs()`
  - `thermal_stress_realobs()`
- 수정 목적:
  실로그 기준 채널 우선순위/정규화 범위/offset 반영

2) RealObs 보상/종료 기준 조정
- 파일:
  - `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/mdp/rewards/phm.py`
  - `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/mdp/terminations/health.py`
  - `unitree_go2_phm/source/unitree_go2_phm/unitree_go2_phm/tasks/manager_based/unitree_go2_phm/unitree_go2_realobs_env_cfg.py`
- 주요 함수/파라미터:
  - `thermal_margin_reward_realobs()`
  - `thermal_runaway(...)`
  - `brownout_enter_v`, `brownout_recover_v`, thermal threshold
- 수정 목적:
  실장비 보호 기준과 코드 기준 정렬

3) Replay governor 임계/필터 조정
- 파일:
  - `unitree_go2_phm/scripts/rsl_rl/replay_utils.py`
  - `unitree_go2_phm/scripts/rsl_rl/evaluate_replay.py`
- 주요 클래스/인자:
  - `GovernorConfig`
  - CLI options (`--temp_warn_c`, `--cell_warn_v`, `--volt_tau_s` 등)
- 수정 목적:
  실로그 기반 임계/동특성 반영

4) 평가 결과 해석 semantics 동기화
- 파일:
  - `unitree_go2_phm/scripts/rsl_rl/evaluate.py`
- 주요 함수:
  - `_thermal_failure_params()`
  - `_temperature_tensor_for_eval()`
  - `apply_scenario()`
- 수정 목적:
  coil vs case 의미가 결과표에서 섞이지 않도록 고정

5) 실로봇 브리지(신규 구현 필요)
- 현재 상태:
  repo에는 SDK 배치 체크와 요구사항 문서까지는 있음.
- 신규 권장 파일:
  - `unitree_go2_phm/scripts/real/run_governor_live.py`
  - `unitree_go2_phm/scripts/real/log_to_replay_csv.py`
  - `unitree_go2_phm/scripts/real/offline_replay_eval_from_log.py`
- 최소 기능:
  500Hz LowState ingest -> 50Hz governor loop -> stop reason logging -> CSV/JSON 출력


========================================================================
19장. 리스크 레지스터 (문제 생길 가능성 + 대응)
========================================================================

19.1 기술 리스크

1) 온도 semantics 혼동
- 위험: coil/case 비교 혼선
- 대응: 메타파일 + 표 캡션에 명시

2) latent 과의존
- 위험: 실로봇 claim 약화
- 대응: 메인 결과를 RealObs/replay 지표 중심으로 구성

3) replay 시나리오 편향
- 위험: 특정 명령에만 맞춘 결과
- 대응: 3개 이상의 서로 다른 명령 프로파일 유지


19.2 실험 리스크

1) seed 변동성
- 위험: 우연한 성능 차이를 기여로 오해
- 대응: seed>=3 권장, 평균+표준편차 보고

2) checkpoint 선택 편향
- 위험: 유리한 체크포인트만 선택
- 대응: 사전 규칙(최종 iteration 또는 best validation 룰) 고정

3) 실행 실패/중단
- 위험: 장시간 학습 중단으로 일정 지연
- 대응: run별 로그/체크포인트 자동 저장 확인


19.3 논문 리스크

1) 공헌점 불명확
- 대응: "PHM-aware 관측/보상 + governor replay 검증"으로 일관 메시지

2) 과장 claim
- 대응: 측정 가능 채널 기반 문장으로 제한

3) 리뷰어 재현성 지적
- 대응: 명령어/시드/설정/출력 경로를 문서화


========================================================================
20장. 투고 전략 (PHM vs IROS 계열)
========================================================================

20.1 PHM 성향 학회에 맞는 포지션

강조:
- health-aware control
- degradation scenario robustness
- measurable-channel 중심 안전 지표
- governor의 practical safety layer

주의:
- 로봇 제어 기교보다 "건전성/안전성 지표 개선" 중심으로 스토리


20.2 IROS/로보틱스 성향 포지션

강조:
- locomotion robustness under degraded actuation
- teacher-student transfer
- real-observable policy deployment path

주의:
- PHM 용어를 과도하게 전면화하면 메시지 분산 가능


========================================================================
21장. 교수님께 보여줄 숫자 최소 세트 (핵심 표)
========================================================================

표 A (시나리오 성능):
- Fresh/Used/Aged/Critical
- Survival, TrackErr, MeanPower, MaxTemp
- Baseline vs PHM(or RealObs)

표 B (Replay ON/OFF):
- completed_rate
- yaw_mae_exec
- time_temp_over_warn_s
- vpack_min_v / vcell_min_v
- energy_j

표 C (Fault replay):
- fault 유무, governor 유무 조합별 결과


========================================================================
22장. 교수님 미팅 전날 체크리스트 (실전)
========================================================================

1) 발표자료 12장 완성
2) 각 그림/표에 데이터 원천 파일 경로 명시
3) 온도 semantics 표기 확인
4) baseline 공정성 문장 준비
5) sim-to-real 리스크와 완화전략 1페이지 준비
6) 향후 2주 실행 계획 1페이지 준비
7) 교수님 의사결정 요청 3개 문항 준비


========================================================================
23장. 내가 지금 당장 해야 할 액션 아이템 (요약)
========================================================================

1) 이 문서를 바탕으로 발표 슬라이드 제작
2) PHM/Baseline/RealObs 실험 진행 현황 표 작성
3) replay ON/OFF + fault 결과를 표 형태로 정리
4) "측정가능 채널 기반 claim 문장"을 미리 초안 작성
5) 교수님 미팅에서 결정받아야 할 항목을 마지막 슬라이드에 명시


========================================================================
24장. 결론 (교수님께 드릴 최종 메시지)
========================================================================

현재 상태:
1) 코드 구조는 PHM 물리-관측-보상-평가가 일관되게 연결됨
2) 메인 논문 트랙(RealObs + replay governor) 준비가 되어 있음
3) latent 지표는 보조/teacher 용도로 분리 가능

앞으로 필요한 것:
1) 교수님과 실험 우선순위 확정
2) seed/ablation 최소 세트 마감
3) 메인 표/그림 고정 후 논문 본문 작성

핵심 문장:
"이 프로젝트는 '열화 상황에서 안전하게 버티는 보행'을
 정량지표로 증명할 수 있는 형태로 거의 정리되어 있습니다.
 이제 남은 것은 실험 우선순위 확정과 결과 표준화입니다."


========================================================================
부록 A. 현재 코드 기준 핵심 임계값 모음
========================================================================

Replay governor 기본:
- temp warn/crit/stop = 65/70/72 C
- cell warn/soft/hard = 3.20/3.05/3.00 V
- pack hard stop = 24.5 V
- yaw exponent = 1.5

RealObs 환경:
- brownout source = sensor_voltage
- brownout enter/recover = 24.5 / 25.0 V
- thermal termination = case proxy 기준(72 C)

Privileged PHM 환경:
- thermal critical around 90 C termination 설정
- thermal derating / fatigue derating 반영

상수 보정 문서:
- `REAL_CONSTANTS_CALIBRATION_KR.txt` (실데이터로 맞춰야 할 상수/코드 위치/우선순위)


========================================================================
부록 B. 실로봇 준비 메모
========================================================================

SDK 위치:
- third_party/unitree_sdk2/

점검:
- python unitree_go2_phm/scripts/real/check_sdk_setup.py

실로봇 로그 요구사항:
- unitree_go2_phm/scripts/real/REAL_LOG_REQUIREMENTS.txt 참조

메인 원칙:
- 실로봇 claim은 측정 채널로 계산 가능한 지표만 사용
